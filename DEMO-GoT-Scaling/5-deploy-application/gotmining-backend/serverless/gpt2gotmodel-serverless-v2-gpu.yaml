apiVersion: serving.knative.dev/v1
kind: Service
metadata:
  name: gpt2gotmodel
  labels:
    app: gpt2gotmodel
    version: v2
    app.kubernetes.io/part-of: gotmining
    serving.knative.dev/visibility: cluster-local
  annotations:
    haproxy.router.openshift.io/timeout: 240s
spec:
  template:
    metadata:
      annotations:
        # minimum --> serverless is not necessarily scaling to 0
        autoscaling.knative.dev/minScale: "1"
        # maximum of pods
        autoscaling.knative.dev/maxScale: "15"
        # handle 1 requests per pod
        autoscaling.knative.dev/target: "1"
    spec:
      affinity:
        nodeAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 100
              preference:
                matchExpressions:
                  - key: gpu
                    operator: Exists
      containers:
      - name: gotmining-backend
        image: quay.io/mdargatz/gotmininggpt2:small
        imagePullPolicy: Always
        ports:
        - containerPort: 8080
